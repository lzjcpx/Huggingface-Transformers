{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Tokenizer 基本使用</h2>",
   "id": "7d3c42e1de4b4a36"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:19:22.248029Z",
     "start_time": "2024-06-24T08:19:22.230045Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import AutoTokenizer",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:19:30.507553Z",
     "start_time": "2024-06-24T08:19:30.501571Z"
    }
   },
   "cell_type": "code",
   "source": "sen = \"弱小的我也有大梦想!\"",
   "id": "d7381c8aa345784a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Step1 加载与保存</h2>",
   "id": "9e3308ea7aa43d4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:19:59.489275Z",
     "start_time": "2024-06-24T08:19:58.528452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 从HuggingFace加载，输入模型名称，即可加载对于的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "tokenizer"
   ],
   "id": "c1d71202f87cbe5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:20:58.701299Z",
     "start_time": "2024-06-24T08:20:58.658414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenizer 保存到本地\n",
    "tokenizer.save_pretrained(\"./roberta_tokenizer\")"
   ],
   "id": "b6e5f9b09865371",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./roberta_tokenizer\\\\tokenizer_config.json',\n",
       " './roberta_tokenizer\\\\special_tokens_map.json',\n",
       " './roberta_tokenizer\\\\vocab.txt',\n",
       " './roberta_tokenizer\\\\added_tokens.json',\n",
       " './roberta_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:24:11.852172Z",
     "start_time": "2024-06-24T08:24:11.821255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 从本地加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./roberta_tokenizer/\")\n",
    "tokenizer"
   ],
   "id": "264e419483ea2951",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Step2 句子分词</h2>",
   "id": "4ada9b6532353c3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:24:32.023580Z",
     "start_time": "2024-06-24T08:24:32.007613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokens = tokenizer.tokenize(sen)\n",
    "tokens"
   ],
   "id": "4353fd9c77dbb699",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['弱', '小', '的', '我', '也', '有', '大', '梦', '想', '!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Step3 查看词典</h2>",
   "id": "98c127678873103d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:24:54.506115Z",
     "start_time": "2024-06-24T08:24:54.461232Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab",
   "id": "d6c7592a2ab0f380",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##厩': 14395,\n",
       " '##莖': 18861,\n",
       " '匝': 1268,\n",
       " '##埕': 14873,\n",
       " '##袒': 19209,\n",
       " '匯': 1274,\n",
       " '飾': 7617,\n",
       " '遺': 6909,\n",
       " '赖': 6609,\n",
       " '##注': 16857,\n",
       " '##逛': 19916,\n",
       " '材': 3332,\n",
       " '##∣': 13536,\n",
       " '缤': 5364,\n",
       " '55': 8222,\n",
       " '誇': 6288,\n",
       " '戸': 2788,\n",
       " '##婀': 15093,\n",
       " 'ces': 9818,\n",
       " '～10': 11115,\n",
       " '##ｂ': 12641,\n",
       " '尺': 2223,\n",
       " '绸': 5339,\n",
       " '姻': 2012,\n",
       " '##坤': 14844,\n",
       " '##man': 8490,\n",
       " '##歪': 16696,\n",
       " '##籁': 18147,\n",
       " '##吽': 14490,\n",
       " '##逵': 19926,\n",
       " '饯': 7651,\n",
       " '##01': 8665,\n",
       " '亲': 779,\n",
       " '幾': 2407,\n",
       " '##night': 12734,\n",
       " 'きなしソフトサーヒス': 11811,\n",
       " '##刘': 14212,\n",
       " '##麾': 20997,\n",
       " '怪': 2597,\n",
       " '##痕': 17632,\n",
       " '鬟': 7781,\n",
       " '##uch': 12752,\n",
       " '##愜': 15753,\n",
       " '慌': 2707,\n",
       " '##搬': 16078,\n",
       " '##胱': 18594,\n",
       " '##埗': 14874,\n",
       " '杭': 3343,\n",
       " '诿': 6441,\n",
       " '萃': 5842,\n",
       " 'usb': 8335,\n",
       " '際': 7396,\n",
       " '##氐': 16752,\n",
       " '##zl': 12961,\n",
       " '侵': 909,\n",
       " '##fu': 12043,\n",
       " '##东': 13748,\n",
       " '##遼': 19967,\n",
       " '錯': 7097,\n",
       " '##とは': 11896,\n",
       " '玷': 4388,\n",
       " '0fork': 8453,\n",
       " '毀': 3672,\n",
       " '酿': 7001,\n",
       " '##boy': 11287,\n",
       " '耦': 5453,\n",
       " '胁': 5516,\n",
       " '##shot': 11125,\n",
       " 'g4g': 10613,\n",
       " '##lan': 9475,\n",
       " '##ith': 11440,\n",
       " '##ᵃ': 13489,\n",
       " '##霓': 20513,\n",
       " '塾': 1860,\n",
       " '筑': 5029,\n",
       " '##ロ': 10068,\n",
       " '妞': 1977,\n",
       " '柱': 3393,\n",
       " 'channel': 11261,\n",
       " '##嗲': 14697,\n",
       " '##憲': 15797,\n",
       " '##迂': 19868,\n",
       " '##邑': 19980,\n",
       " '##食': 20665,\n",
       " '##澆': 17125,\n",
       " '##３': 9089,\n",
       " '##胤': 18587,\n",
       " '##统': 18377,\n",
       " '嗽': 1644,\n",
       " '昨': 3219,\n",
       " '饕': 7642,\n",
       " '昕': 3213,\n",
       " '##揉': 16044,\n",
       " '挚': 2907,\n",
       " 'qe': 11534,\n",
       " 'gap': 10130,\n",
       " '##姫': 15066,\n",
       " '##-': 13329,\n",
       " '##邊': 19977,\n",
       " '##霎': 20510,\n",
       " '##a5': 12540,\n",
       " '##暗': 16323,\n",
       " '##＠': 21088,\n",
       " 'brandt': 12855,\n",
       " '##每': 16737,\n",
       " '##刚': 14214,\n",
       " '##▂': 13597,\n",
       " '##奇': 14993,\n",
       " '趴': 6640,\n",
       " 'nikkie': 13303,\n",
       " '##てす': 8504,\n",
       " 'af': 11782,\n",
       " '倪': 960,\n",
       " '恰': 2623,\n",
       " 'cma': 12398,\n",
       " '森': 3481,\n",
       " '##滓': 17056,\n",
       " '骤': 7752,\n",
       " '##楔': 16560,\n",
       " 'せからこ': 12150,\n",
       " '##蘿': 19044,\n",
       " '##辻': 19863,\n",
       " '畿': 4537,\n",
       " '斓': 3158,\n",
       " '##樁': 16612,\n",
       " '##钉': 20209,\n",
       " '##郜': 20006,\n",
       " '##菖': 18886,\n",
       " '##伊': 13880,\n",
       " '##処': 14186,\n",
       " '##ction': 9116,\n",
       " '綠': 5199,\n",
       " '##諒': 19372,\n",
       " '外': 1912,\n",
       " '##餅': 20676,\n",
       " '##辇': 19833,\n",
       " 'pinkoi': 11941,\n",
       " '##秩': 17971,\n",
       " '##秸': 17975,\n",
       " '褫': 6193,\n",
       " 'hu': 12199,\n",
       " '##ss': 8565,\n",
       " '襟': 6199,\n",
       " '堇': 1832,\n",
       " '##bian': 11092,\n",
       " '榫': 3530,\n",
       " '##陀': 20408,\n",
       " '##瞑': 17793,\n",
       " '视': 6228,\n",
       " '##書': 16349,\n",
       " '##葯': 18932,\n",
       " 'tue': 8483,\n",
       " '##mple': 12581,\n",
       " '嘎': 1652,\n",
       " '阻': 7349,\n",
       " '割': 1200,\n",
       " '##姹': 15068,\n",
       " '##雎': 20478,\n",
       " '锁': 7219,\n",
       " '琼': 4437,\n",
       " '济': 3845,\n",
       " '##mg': 8882,\n",
       " '烟': 4170,\n",
       " '##op': 9133,\n",
       " '##box': 8927,\n",
       " '18k': 10323,\n",
       " 'sophie': 12127,\n",
       " '##栋': 16463,\n",
       " '令': 808,\n",
       " '集': 7415,\n",
       " 'ncc': 8305,\n",
       " 'p': 158,\n",
       " '##喲': 14666,\n",
       " '##楂': 16557,\n",
       " '##焯': 17251,\n",
       " '橡': 3583,\n",
       " '緯': 5229,\n",
       " '绳': 5334,\n",
       " '侄': 888,\n",
       " '##汞': 16792,\n",
       " '##蜀': 19100,\n",
       " '##辆': 19832,\n",
       " 'where': 11703,\n",
       " '桔': 3435,\n",
       " '喜': 1599,\n",
       " '≡': 393,\n",
       " '傚': 992,\n",
       " '葫': 5872,\n",
       " '##劲': 14283,\n",
       " '##孳': 15174,\n",
       " '##窓': 18024,\n",
       " '钻': 7183,\n",
       " '▲topjun': 10263,\n",
       " '壩': 1893,\n",
       " '樺': 3573,\n",
       " '珑': 4400,\n",
       " '##♥': 9177,\n",
       " '##蜗': 19111,\n",
       " '##獗': 17414,\n",
       " '浑': 3847,\n",
       " '楼': 3517,\n",
       " '##═': 13586,\n",
       " '##胃': 18574,\n",
       " '##露': 20520,\n",
       " 'stage': 12731,\n",
       " '152': 9653,\n",
       " '##姑': 15053,\n",
       " '##砾': 17850,\n",
       " '囉': 1717,\n",
       " '##莞': 18863,\n",
       " '汝': 3734,\n",
       " '##蔺': 18983,\n",
       " 'ち': 552,\n",
       " '浬': 3858,\n",
       " '烁': 4161,\n",
       " '##艙': 18733,\n",
       " '##半': 14345,\n",
       " '##誤': 19356,\n",
       " '##韩': 20563,\n",
       " '佃': 851,\n",
       " '##儲': 14090,\n",
       " '镀': 7249,\n",
       " 'unt': 13003,\n",
       " 'institute': 11205,\n",
       " '｛': 8077,\n",
       " '##势': 14289,\n",
       " '##丞': 13750,\n",
       " '鰾': 7817,\n",
       " 'education': 12727,\n",
       " '##亙': 13818,\n",
       " '##獐': 17412,\n",
       " '##琉': 17474,\n",
       " '##蠟': 19166,\n",
       " '##襬': 19259,\n",
       " '##缜': 18417,\n",
       " '##漓': 17084,\n",
       " '##锟': 20290,\n",
       " '曙': 3282,\n",
       " '？': 8043,\n",
       " '##ァ': 13680,\n",
       " '蛛': 6033,\n",
       " '##噁': 14736,\n",
       " '幺': 2403,\n",
       " '庫': 2430,\n",
       " '畝': 4524,\n",
       " '##ters': 12017,\n",
       " '1937': 9166,\n",
       " '蒐': 5883,\n",
       " '孪': 2112,\n",
       " 'b2b': 9493,\n",
       " '##为': 13768,\n",
       " '##担': 15914,\n",
       " '绽': 5342,\n",
       " '##93': 9676,\n",
       " '1389': 12853,\n",
       " '嬤': 2085,\n",
       " '巩': 2343,\n",
       " '銭': 7074,\n",
       " 'emba': 10360,\n",
       " '焜': 4191,\n",
       " 'xl': 10657,\n",
       " '##tel': 11246,\n",
       " 'eeworld': 12490,\n",
       " 'p10': 10405,\n",
       " '##弹': 15543,\n",
       " '##膛': 18662,\n",
       " '##闊': 20352,\n",
       " '##渴': 17008,\n",
       " '##晨': 16304,\n",
       " '##淞': 16965,\n",
       " 'dns': 9580,\n",
       " '##趁': 19687,\n",
       " '庁': 2409,\n",
       " '釜': 7035,\n",
       " '淖': 3904,\n",
       " '勿': 1257,\n",
       " '徇': 2522,\n",
       " '##佳': 13938,\n",
       " '##寶': 15245,\n",
       " '衣': 6132,\n",
       " '182': 9952,\n",
       " '##伢': 13895,\n",
       " '##瞪': 17802,\n",
       " '◎': 473,\n",
       " '##gas': 12400,\n",
       " '##ron': 8991,\n",
       " '##^': 13342,\n",
       " '②': 406,\n",
       " '咖': 1476,\n",
       " '##ms': 8884,\n",
       " 'b3': 12790,\n",
       " '##痔': 17631,\n",
       " '##蚌': 19069,\n",
       " '↔': 372,\n",
       " '馋': 7669,\n",
       " '##諺': 19386,\n",
       " '##拣': 15937,\n",
       " '##火': 17182,\n",
       " '##碴': 17881,\n",
       " 'q3': 10982,\n",
       " '饱': 7653,\n",
       " '##耍': 18503,\n",
       " '257': 11027,\n",
       " '溢': 3980,\n",
       " '緣': 5225,\n",
       " '##苣': 18791,\n",
       " '##ett': 13151,\n",
       " '羿': 5418,\n",
       " 'eba': 11129,\n",
       " '##尚': 15270,\n",
       " '戦': 2778,\n",
       " '##追': 19898,\n",
       " '##焙': 17246,\n",
       " '鞋': 7490,\n",
       " '痈': 4569,\n",
       " 'ろ': 582,\n",
       " '旃': 3179,\n",
       " '沥': 3769,\n",
       " '##縴': 18299,\n",
       " '諗': 6317,\n",
       " '##艮': 18735,\n",
       " '##邝': 19984,\n",
       " '##戌': 15821,\n",
       " '↓↓↓': 9010,\n",
       " 'にも': 9328,\n",
       " '##闆': 20350,\n",
       " '##閔': 20337,\n",
       " '##95': 9102,\n",
       " 'ai': 8578,\n",
       " '##耗': 18507,\n",
       " '##靼': 20545,\n",
       " '##鏖': 20180,\n",
       " '##ｕ': 21098,\n",
       " '塑': 1848,\n",
       " '谕': 6460,\n",
       " 'dior': 8639,\n",
       " '##埂': 14868,\n",
       " '##畝': 17581,\n",
       " '袂': 6146,\n",
       " '徜': 2536,\n",
       " '3～4': 12907,\n",
       " '##阖': 20392,\n",
       " 'nbapop': 12188,\n",
       " '##悟': 15697,\n",
       " '##诣': 19476,\n",
       " '##77': 8959,\n",
       " '繚': 5253,\n",
       " 'kicstart2': 12614,\n",
       " '来': 3341,\n",
       " '绕': 5312,\n",
       " '1914': 9837,\n",
       " '柴': 3395,\n",
       " '340': 10049,\n",
       " '汞': 3735,\n",
       " '诶': 6434,\n",
       " 'swissinfo': 10661,\n",
       " '##pad': 10730,\n",
       " '240': 8821,\n",
       " 'vmalife': 10823,\n",
       " '##运': 19874,\n",
       " 'ス': 605,\n",
       " '擾': 3101,\n",
       " '熄': 4219,\n",
       " 'dan': 11404,\n",
       " '##舸': 18726,\n",
       " '鉗': 7059,\n",
       " '墮': 1876,\n",
       " '235': 8593,\n",
       " '##乙': 13791,\n",
       " 'bruce': 12897,\n",
       " '卡': 1305,\n",
       " '吠': 1413,\n",
       " '219': 10453,\n",
       " '兵': 1070,\n",
       " '##ます': 8643,\n",
       " '2600': 10496,\n",
       " '梓': 3452,\n",
       " 'event': 10992,\n",
       " '##滬': 17071,\n",
       " '##闭': 20365,\n",
       " '→': 370,\n",
       " '日': 3189,\n",
       " 'japan': 9151,\n",
       " '##镰': 20323,\n",
       " '养': 1075,\n",
       " '架': 3373,\n",
       " '彩': 2506,\n",
       " '隽': 7409,\n",
       " '##评': 19454,\n",
       " '滇': 3995,\n",
       " '琶': 4435,\n",
       " '##栖': 16468,\n",
       " '##溼': 17047,\n",
       " '##ように': 10847,\n",
       " '##xp': 11379,\n",
       " '##囑': 14777,\n",
       " '琛': 4422,\n",
       " '##92': 9595,\n",
       " '##wf': 12242,\n",
       " '柯': 3392,\n",
       " 'pink': 12016,\n",
       " '##媧': 15115,\n",
       " '##ᄉ': 13462,\n",
       " '##嬅': 15136,\n",
       " '##榨': 16586,\n",
       " 'は１ヶ': 11638,\n",
       " '##fun': 11222,\n",
       " '##裏': 19223,\n",
       " '##驴': 20780,\n",
       " '##錳': 20156,\n",
       " '##侍': 13949,\n",
       " '##嫣': 15130,\n",
       " '黛': 7950,\n",
       " 'eyes': 12909,\n",
       " '##勵': 14309,\n",
       " '##洶': 16887,\n",
       " '##にお': 12337,\n",
       " '##リー': 10535,\n",
       " '梅': 3449,\n",
       " '抚': 2836,\n",
       " '##讳': 19440,\n",
       " '##cer': 10326,\n",
       " '橋': 3578,\n",
       " 'big': 9193,\n",
       " '均': 1772,\n",
       " '##夫': 14980,\n",
       " '忿': 2576,\n",
       " '蜓': 6052,\n",
       " '##就': 15275,\n",
       " '##锅': 20279,\n",
       " '蝎': 6070,\n",
       " '阜': 7338,\n",
       " '##bay': 13200,\n",
       " '縮': 5240,\n",
       " 'kate': 11058,\n",
       " '##詬': 19335,\n",
       " '缱': 5372,\n",
       " '##3': 8152,\n",
       " '慕': 2710,\n",
       " '##鯨': 20866,\n",
       " '撃': 3048,\n",
       " '椪': 3494,\n",
       " 'td': 9287,\n",
       " '爷': 4267,\n",
       " '粉': 5106,\n",
       " '蝶': 6079,\n",
       " '駕': 7690,\n",
       " '##浜': 16910,\n",
       " '##禎': 17942,\n",
       " '指': 2900,\n",
       " '##菁': 18878,\n",
       " '##賀': 19588,\n",
       " '禍': 4884,\n",
       " 'mc': 10341,\n",
       " '##係': 13970,\n",
       " '##镉': 20310,\n",
       " '島': 2294,\n",
       " '賜': 6541,\n",
       " '##招': 15932,\n",
       " '■': 459,\n",
       " '玥': 4380,\n",
       " '类': 5102,\n",
       " '灰': 4129,\n",
       " '鶩': 7872,\n",
       " '##０': 8569,\n",
       " '1871': 13262,\n",
       " '汽': 3749,\n",
       " '518': 8739,\n",
       " '##仿': 13877,\n",
       " '##寢': 15234,\n",
       " '##→': 10057,\n",
       " '2900': 13044,\n",
       " '葦': 5870,\n",
       " '邁': 6914,\n",
       " '怎': 2582,\n",
       " 'fifa': 12130,\n",
       " '##动': 14277,\n",
       " '##琨': 17483,\n",
       " '勘': 1242,\n",
       " '##莽': 18875,\n",
       " '険': 7381,\n",
       " '块': 1779,\n",
       " '##苋': 18777,\n",
       " 'ｊ': 8060,\n",
       " '##賤': 19604,\n",
       " '##后': 14457,\n",
       " '泰': 3805,\n",
       " '绛': 5316,\n",
       " '##骑': 20801,\n",
       " '楣': 3508,\n",
       " '##bi': 9350,\n",
       " '##侖': 13952,\n",
       " '妇': 1967,\n",
       " '歯': 3640,\n",
       " '##喺': 14672,\n",
       " '滓': 3999,\n",
       " '2800': 10347,\n",
       " '飞': 7607,\n",
       " 'フ': 621,\n",
       " '叙': 1360,\n",
       " '邪': 6932,\n",
       " '隅': 7383,\n",
       " '锭': 7240,\n",
       " '##甌': 17546,\n",
       " '贫': 6577,\n",
       " '##zon': 10623,\n",
       " '1890': 11787,\n",
       " '饮': 7650,\n",
       " 'kimi': 11966,\n",
       " '##攸': 16177,\n",
       " '##蓋': 18958,\n",
       " 'dyson': 12730,\n",
       " '帷': 2381,\n",
       " '秆': 4902,\n",
       " '##吵': 14484,\n",
       " '娛': 2024,\n",
       " '##补': 19190,\n",
       " '##冬': 14157,\n",
       " '##赋': 19659,\n",
       " '撥': 3060,\n",
       " '証': 6264,\n",
       " '闻': 7319,\n",
       " 'watch': 9114,\n",
       " '##徽': 15608,\n",
       " '愁': 2687,\n",
       " '吕': 1406,\n",
       " '##ris': 9848,\n",
       " '铄': 7191,\n",
       " '##⁄': 13510,\n",
       " '##哟': 14575,\n",
       " '##枇': 16412,\n",
       " '##また': 13150,\n",
       " '##爍': 17313,\n",
       " '##疖': 17601,\n",
       " '##菈': 18881,\n",
       " '##梧': 16515,\n",
       " '1978': 8774,\n",
       " '癫': 4626,\n",
       " '##廊': 15500,\n",
       " '##鲫': 20893,\n",
       " 'man': 8791,\n",
       " '盯': 4681,\n",
       " '##舶': 18724,\n",
       " '##谄': 19502,\n",
       " '嶇': 2324,\n",
       " 'nb': 9254,\n",
       " '亨': 773,\n",
       " '篮': 5074,\n",
       " '猙': 4337,\n",
       " '僖': 1011,\n",
       " '壅': 1881,\n",
       " 'lu': 12015,\n",
       " 'mobil': 12572,\n",
       " '##瓏': 17533,\n",
       " 'よ': 577,\n",
       " '##侥': 13959,\n",
       " '覬': 6218,\n",
       " '##驷': 20782,\n",
       " '1905': 10196,\n",
       " '##鳕': 20904,\n",
       " '润': 3883,\n",
       " '##ves': 11084,\n",
       " '##泞': 16851,\n",
       " 'credit': 12241,\n",
       " '##頑': 20579,\n",
       " '[unused71]': 71,\n",
       " '##诲': 19488,\n",
       " '##匍': 14319,\n",
       " '怅': 2580,\n",
       " '##功': 14273,\n",
       " 'sarah': 12455,\n",
       " '桂': 3424,\n",
       " '蔗': 5915,\n",
       " '增': 1872,\n",
       " '歡': 3631,\n",
       " '纽': 5294,\n",
       " 'basic': 12309,\n",
       " '##敦': 16199,\n",
       " 'energy': 11939,\n",
       " '##飲': 20671,\n",
       " '##豔': 19551,\n",
       " '侠': 899,\n",
       " '16gb': 11340,\n",
       " '##31': 8805,\n",
       " '<T>': 105,\n",
       " 'е': 238,\n",
       " '頃': 7516,\n",
       " '贅': 6556,\n",
       " '槌': 3540,\n",
       " '醜': 7011,\n",
       " '##cake': 12814,\n",
       " '##譏': 19408,\n",
       " '##迩': 19888,\n",
       " '⒋': 423,\n",
       " '##泽': 16870,\n",
       " '##汨': 16797,\n",
       " '##舞': 18716,\n",
       " '##蟄': 19149,\n",
       " '##鏢': 20186,\n",
       " '##登': 17690,\n",
       " 'ebd': 8539,\n",
       " '##型': 14855,\n",
       " '##♪': 9458,\n",
       " '柚': 3384,\n",
       " 'ftp': 9195,\n",
       " '##请': 19492,\n",
       " 'bug': 8761,\n",
       " '##嵬': 15377,\n",
       " '##母': 16735,\n",
       " '##风': 20656,\n",
       " '軒': 6726,\n",
       " '##師': 15431,\n",
       " '儡': 1031,\n",
       " '##燈': 17293,\n",
       " 'bloomberg': 10313,\n",
       " '丙': 688,\n",
       " 'me': 8450,\n",
       " '♂': 487,\n",
       " 'ぇ': 538,\n",
       " '170': 8725,\n",
       " '##ok': 9185,\n",
       " '笋': 5008,\n",
       " '飒': 7600,\n",
       " '磯': 4838,\n",
       " '跑': 6651,\n",
       " '針': 7036,\n",
       " '晒': 3235,\n",
       " 'modern': 12862,\n",
       " '##対': 15251,\n",
       " '5mm': 9394,\n",
       " '##懿': 15817,\n",
       " '##旎': 16240,\n",
       " '##玄': 17428,\n",
       " '##綵': 18265,\n",
       " '蘇': 5979,\n",
       " '##協': 14352,\n",
       " '##暱': 16330,\n",
       " '##诊': 19459,\n",
       " '##肪': 18562,\n",
       " '##醮': 20074,\n",
       " '悅': 2633,\n",
       " '擄': 3077,\n",
       " '##犒': 17359,\n",
       " '##窃': 18018,\n",
       " '##绘': 18370,\n",
       " 'mi': 10551,\n",
       " '##順': 20575,\n",
       " '##痙': 17634,\n",
       " '##樵': 16627,\n",
       " '##釉': 20081,\n",
       " '##е': 13406,\n",
       " 'シ': 604,\n",
       " 'ت': 264,\n",
       " '玮': 4383,\n",
       " '辑': 6782,\n",
       " '莹': 5816,\n",
       " '##簇': 18134,\n",
       " '##uce': 12051,\n",
       " '③': 407,\n",
       " '##铜': 20255,\n",
       " '##骤': 20809,\n",
       " '##钩': 20231,\n",
       " '##db': 9123,\n",
       " '##nm': 9359,\n",
       " 'かお': 11252,\n",
       " 'pet': 10495,\n",
       " '##瘫': 17668,\n",
       " '##潞': 17110,\n",
       " '##幂': 15443,\n",
       " '搜': 3017,\n",
       " '碇': 4806,\n",
       " 'pepper': 11861,\n",
       " '##．': 21082,\n",
       " '○○': 9423,\n",
       " '##蔡': 18975,\n",
       " '##ㆍ': 13724,\n",
       " '##喬': 14662,\n",
       " '##讹': 19445,\n",
       " '##ions': 11137,\n",
       " 'ネ': 617,\n",
       " '##空': 18015,\n",
       " 'pixel': 11688,\n",
       " '##tee': 12729,\n",
       " '##璁': 17517,\n",
       " '湍': 3958,\n",
       " '蓝': 5905,\n",
       " 'quot': 10733,\n",
       " '##2014': 8951,\n",
       " '##窮': 18038,\n",
       " '##hp': 9990,\n",
       " '矾': 4770,\n",
       " '凇': 1115,\n",
       " '##cp': 11057,\n",
       " '##｛': 21101,\n",
       " '禿': 4898,\n",
       " '菏': 5827,\n",
       " '##ene': 10600,\n",
       " '厉': 1326,\n",
       " '##屯': 15311,\n",
       " '莪': 5810,\n",
       " '##狭': 17382,\n",
       " '##🔥': 21125,\n",
       " '##涿': 16951,\n",
       " '355': 11753,\n",
       " '拦': 2882,\n",
       " 'つ': 554,\n",
       " '17': 8126,\n",
       " '##葵': 18935,\n",
       " '租': 4909,\n",
       " '吏': 1401,\n",
       " '冾': 1111,\n",
       " '依': 898,\n",
       " '##熠': 17283,\n",
       " '頌': 7520,\n",
       " '##bell': 13110,\n",
       " '##堺': 14901,\n",
       " '筹': 5040,\n",
       " '##碼': 17883,\n",
       " 'ba': 10322,\n",
       " '##刃': 14202,\n",
       " '911': 9911,\n",
       " '襁': 6197,\n",
       " '##尉': 15259,\n",
       " '##ニ': 13689,\n",
       " '##庆': 15469,\n",
       " 'di': 9796,\n",
       " '##箱': 18113,\n",
       " '##攣': 16169,\n",
       " '##便': 13969,\n",
       " '##鼐': 21017,\n",
       " '漫': 4035,\n",
       " '睑': 4713,\n",
       " '##衩': 19192,\n",
       " '##恆': 15661,\n",
       " '##溅': 17029,\n",
       " '##侧': 13961,\n",
       " '##pe': 8619,\n",
       " '决': 1104,\n",
       " '怔': 2585,\n",
       " '##灯': 17185,\n",
       " '[unused52]': 52,\n",
       " '幟': 2392,\n",
       " '妳': 1986,\n",
       " '漢': 4031,\n",
       " '较': 6772,\n",
       " '##nor': 12245,\n",
       " '膝': 5607,\n",
       " '##傍': 14045,\n",
       " '##care': 11014,\n",
       " '蕉': 5933,\n",
       " '##嶂': 15379,\n",
       " '犒': 4302,\n",
       " '##mes': 13060,\n",
       " '##二': 13810,\n",
       " '##室': 15204,\n",
       " '##苍': 18778,\n",
       " '##宽': 15217,\n",
       " 'う': 537,\n",
       " '醺': 7020,\n",
       " '鉴': 7063,\n",
       " '##ل': 13435,\n",
       " '鱼': 7824,\n",
       " '##表': 19191,\n",
       " 'you': 8357,\n",
       " 'い': 536,\n",
       " '##碾': 17884,\n",
       " '##閡': 20339,\n",
       " '##隆': 20441,\n",
       " 'cloud': 10279,\n",
       " '##祁': 17911,\n",
       " '啸': 1580,\n",
       " '蚵': 6023,\n",
       " '而': 5445,\n",
       " '##，': 21080,\n",
       " '191': 10330,\n",
       " '128gb': 12336,\n",
       " '##離': 20488,\n",
       " '##tw': 12278,\n",
       " '##喋': 14649,\n",
       " '##nt': 8511,\n",
       " '##佘': 13921,\n",
       " '##鹭': 20972,\n",
       " '尊': 2203,\n",
       " '車': 6722,\n",
       " '##臼': 18696,\n",
       " '##斃': 16208,\n",
       " '##假': 14026,\n",
       " '##界': 17575,\n",
       " '##脛': 18616,\n",
       " '噔': 1683,\n",
       " 'chang': 11680,\n",
       " 'cafe': 8377,\n",
       " '##傚': 14049,\n",
       " '##ㄋ': 13709,\n",
       " '##姒': 15054,\n",
       " 'mysql': 9108,\n",
       " '##醛': 20067,\n",
       " '##胥': 18588,\n",
       " '7': 128,\n",
       " '属': 2247,\n",
       " '卢': 1306,\n",
       " '▶': 466,\n",
       " '措': 2974,\n",
       " '##365': 10422,\n",
       " '戕': 2771,\n",
       " '爲': 4264,\n",
       " '080': 12365,\n",
       " '##敝': 16195,\n",
       " '啤': 1566,\n",
       " '##此': 16691,\n",
       " '##残': 16712,\n",
       " '箏': 5046,\n",
       " '##畀': 17573,\n",
       " '##悄': 15689,\n",
       " '齋': 7969,\n",
       " 'chicago': 10268,\n",
       " '3': 124,\n",
       " '央': 1925,\n",
       " '##～7': 12681,\n",
       " '021': 10385,\n",
       " '##竟': 18051,\n",
       " '速': 6862,\n",
       " 'v3': 10066,\n",
       " 'tbs': 11773,\n",
       " '##▌': 13603,\n",
       " '##閣': 20341,\n",
       " '彦': 2504,\n",
       " '洙': 3820,\n",
       " '犀': 4297,\n",
       " '##＃': 21072,\n",
       " '屯': 2254,\n",
       " '1932': 9737,\n",
       " '##暨': 16327,\n",
       " '##sy': 10178,\n",
       " '##縝': 18294,\n",
       " '骚': 7746,\n",
       " '（': 8020,\n",
       " '##习': 13796,\n",
       " '##洩': 16881,\n",
       " '1906': 10959,\n",
       " '##擞': 16145,\n",
       " 'xp': 8766,\n",
       " '##ハー': 10977,\n",
       " '##旗': 16243,\n",
       " '##嘴': 14730,\n",
       " 'step4': 9504,\n",
       " '葱': 5876,\n",
       " '蒿': 5896,\n",
       " '麋': 7924,\n",
       " '##hat': 12063,\n",
       " '##～3': 12617,\n",
       " '##慢': 15771,\n",
       " '俨': 929,\n",
       " '呛': 1448,\n",
       " '句': 1368,\n",
       " '緒': 5219,\n",
       " 'ipad': 8355,\n",
       " '##04': 9099,\n",
       " 'hpv': 11067,\n",
       " 'java': 8507,\n",
       " '##呓': 14501,\n",
       " 'swatch': 11876,\n",
       " 'icp': 9658,\n",
       " '覚': 6214,\n",
       " '##裡': 19231,\n",
       " 'いて': 11232,\n",
       " '##辣': 19850,\n",
       " '##乞': 13794,\n",
       " '##fx': 13122,\n",
       " '##瘍': 17655,\n",
       " '焊': 4184,\n",
       " 'martin': 10059,\n",
       " '##程': 17980,\n",
       " '##きます': 12506,\n",
       " 'day': 8542,\n",
       " '啖': 1561,\n",
       " '懲': 2752,\n",
       " 'bella': 13192,\n",
       " '##躯': 19775,\n",
       " '亀': 747,\n",
       " 'cv': 10718,\n",
       " '##pmlast': 12138,\n",
       " '##hia': 12615,\n",
       " '##柱': 16450,\n",
       " '##21': 8650,\n",
       " '##弱': 15540,\n",
       " '并': 2400,\n",
       " '##陨': 20428,\n",
       " '鸞': 7880,\n",
       " 'dd': 10391,\n",
       " 'さん': 10533,\n",
       " '90': 8192,\n",
       " '1934': 9823,\n",
       " '##庾': 15494,\n",
       " '##羲': 18471,\n",
       " '149': 9491,\n",
       " '##ye': 10522,\n",
       " '##飒': 20657,\n",
       " '匿': 1280,\n",
       " '獭': 4361,\n",
       " '蟎': 6095,\n",
       " '##昱': 16279,\n",
       " '2004': 8258,\n",
       " '##樸': 16628,\n",
       " '1973': 9062,\n",
       " '##筋': 18082,\n",
       " 'universal': 13229,\n",
       " '笈': 5007,\n",
       " '翱': 5433,\n",
       " '権': 3565,\n",
       " '瓶': 4486,\n",
       " '莴': 5814,\n",
       " '質': 6549,\n",
       " '##庄': 15468,\n",
       " '##✿': 13640,\n",
       " '##啃': 14610,\n",
       " '##浦': 16912,\n",
       " 'loft': 12751,\n",
       " '##矍': 17811,\n",
       " '##删': 14217,\n",
       " '##苛': 18786,\n",
       " '奂': 1934,\n",
       " '渠': 3940,\n",
       " '腥': 5581,\n",
       " 'e7': 12888,\n",
       " '##淳': 16976,\n",
       " '##甜': 17551,\n",
       " '##ade': 10233,\n",
       " 'miui': 11342,\n",
       " 'village': 12497,\n",
       " '毂': 3674,\n",
       " '驼': 7729,\n",
       " '##商': 14612,\n",
       " '設': 6257,\n",
       " '樟': 3562,\n",
       " '馴': 7683,\n",
       " '歆': 3622,\n",
       " 'boy': 10447,\n",
       " '絢': 5182,\n",
       " '##绪': 18385,\n",
       " '甌': 4489,\n",
       " '晔': 3237,\n",
       " '##肯': 18564,\n",
       " '拘': 2872,\n",
       " '採': 2967,\n",
       " '识': 6399,\n",
       " '##掠': 16023,\n",
       " '##冊': 14141,\n",
       " '##橱': 16643,\n",
       " '##龟': 21048,\n",
       " 'hp': 8853,\n",
       " '##3c': 12031,\n",
       " '堺': 1844,\n",
       " 'course': 12654,\n",
       " '72': 8325,\n",
       " '101vip': 11428,\n",
       " '##rmin': 13116,\n",
       " '##翳': 18491,\n",
       " '酯': 6994,\n",
       " 'xyz': 11266,\n",
       " '澤': 4075,\n",
       " '##lot': 10580,\n",
       " '雳': 7438,\n",
       " '惶': 2684,\n",
       " 'ptt': 9773,\n",
       " '##ㄉ': 13708,\n",
       " '##羚': 18460,\n",
       " '4399': 9922,\n",
       " '##よう': 10177,\n",
       " '獾': 4370,\n",
       " 'times': 9886,\n",
       " 'ⅱ': 364,\n",
       " 'topapp': 10607,\n",
       " '##床': 15471,\n",
       " 'know': 11460,\n",
       " '搞': 3018,\n",
       " '几': 1126,\n",
       " '翳': 5434,\n",
       " '唳': 1549,\n",
       " '訛': 6251,\n",
       " '##虢': 19056,\n",
       " '##おります': 9797,\n",
       " '鯊': 7806,\n",
       " '[unused98]': 98,\n",
       " '澗': 4072,\n",
       " '##呻': 14517,\n",
       " '##蔼': 18985,\n",
       " '##謗': 19396,\n",
       " '圳': 1766,\n",
       " '##颚': 20637,\n",
       " '涟': 3878,\n",
       " '黍': 7943,\n",
       " '串': 706,\n",
       " '5v': 10965,\n",
       " 'はすへて': 11899,\n",
       " '##烨': 17231,\n",
       " '喊': 1591,\n",
       " '曆': 3278,\n",
       " '奥': 1952,\n",
       " '褒': 6187,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:25:37.708868Z",
     "start_time": "2024-06-24T08:25:37.694905Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.vocab_size",
   "id": "c7de19214084c9fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Step4 索引转换</h2>",
   "id": "6fe706683f60918b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:25:58.896947Z",
     "start_time": "2024-06-24T08:25:58.885976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将词序列转换为id序列\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ids"
   ],
   "id": "933f8f06023f89ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:26:29.501710Z",
     "start_time": "2024-06-24T08:26:29.481762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将id序列转换为token序列\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "tokens"
   ],
   "id": "39394148e2e78b9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['弱', '小', '的', '我', '也', '有', '大', '梦', '想', '!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:26:41.806197Z",
     "start_time": "2024-06-24T08:26:41.798221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将token序列转换为string\n",
    "str_sen = tokenizer.convert_tokens_to_string(tokens)\n",
    "str_sen"
   ],
   "id": "1459b8376482de1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'弱 小 的 我 也 有 大 梦 想!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h3>更便捷的实现方式</h3>",
   "id": "106f744d26bd778f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:27:34.791378Z",
     "start_time": "2024-06-24T08:27:34.774392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将字符串转换为id序列，又称之为编码\n",
    "ids = tokenizer.encode(sen, add_special_tokens=False)\n",
    "ids"
   ],
   "id": "187489cbdb73f179",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:27:12.870748Z",
     "start_time": "2024-06-24T08:27:12.857787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 将id序列转换为字符串，又称之为解码\n",
    "str_sen = tokenizer.decode(ids, skip_special_tokens=False)\n",
    "str_sen"
   ],
   "id": "8a4162ebe2ddc610",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 弱 小 的 我 也 有 大 梦 想! [SEP]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Step5 填充与截断</h2>",
   "id": "478cb230cff4fc15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:28:21.849537Z",
     "start_time": "2024-06-24T08:28:21.832582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 填充\n",
    "ids = tokenizer.encode(sen, padding=\"max_length\", max_length=15)\n",
    "ids"
   ],
   "id": "b95eec44d082fce8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:28:44.070660Z",
     "start_time": "2024-06-24T08:28:44.050713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 截断\n",
    "ids = tokenizer.encode(sen, max_length=5, truncation=True)\n",
    "ids"
   ],
   "id": "1d275de0d89519d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 102]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Step6 其他输入部分</h2>",
   "id": "cf669f66a7e737c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:29:09.096736Z",
     "start_time": "2024-06-24T08:29:09.082772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ids = tokenizer.encode(sen, padding=\"max_length\", max_length=15)\n",
    "ids"
   ],
   "id": "65caa8df931eb78",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:29:49.762359Z",
     "start_time": "2024-06-24T08:29:49.746397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention_mask = [1 if idx != 0 else 0 for idx in ids]\n",
    "token_type_ids = [0] * len(ids)\n",
    "ids, attention_mask, token_type_ids"
   ],
   "id": "85b8365f6ad0f1d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Step7 快速调用方式</h2>",
   "id": "c1b38fe517a24080"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:30:55.166284Z",
     "start_time": "2024-06-24T08:30:55.143313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = tokenizer.encode_plus(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ],
   "id": "49049915d0de34e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:31:06.215907Z",
     "start_time": "2024-06-24T08:31:06.202942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = tokenizer(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ],
   "id": "9cb6b06d385375bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Step8 处理batch数据</h2>",
   "id": "2799190bf944a379"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:31:42.751242Z",
     "start_time": "2024-06-24T08:31:42.738274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sens = [\"弱小的我也有大梦想\",\n",
    "        \"有梦想谁都了不起\",\n",
    "        \"追逐梦想的心，比梦想本身，更可贵\"]\n",
    "res = tokenizer(sens)\n",
    "res"
   ],
   "id": "8b228d89be257b3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102], [101, 3300, 3457, 2682, 6443, 6963, 749, 679, 6629, 102], [101, 6841, 6852, 3457, 2682, 4638, 2552, 8024, 3683, 3457, 2682, 3315, 6716, 8024, 3291, 1377, 6586, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:32:12.186712Z",
     "start_time": "2024-06-24T08:32:12.067806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# 单条循环处理\n",
    "for i in range(1000):\n",
    "    tokenizer(sen)"
   ],
   "id": "b7b3cc5e311cf5c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:32:25.906899Z",
     "start_time": "2024-06-24T08:32:25.859984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# 处理batch数据\n",
    "res = tokenizer([sen] * 1000)"
   ],
   "id": "cb8a99c5082592f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 26.9 ms\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:32:36.746775Z",
     "start_time": "2024-06-24T08:32:36.726791Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer",
   "id": "d1899d423fde7430",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>Fast / Slow Tokenizer</h2>",
   "id": "8831dfc3762a4689"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:33:17.646117Z",
     "start_time": "2024-06-24T08:33:17.633152Z"
    }
   },
   "cell_type": "code",
   "source": "sen = \"弱小的我也有大Dreaming!\"",
   "id": "61f5179321c6f7b8",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:33:25.584394Z",
     "start_time": "2024-06-24T08:33:24.301220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fast_tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "fast_tokenizer"
   ],
   "id": "f9a78b83ac20cbe4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:33:37.069325Z",
     "start_time": "2024-06-24T08:33:36.351924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\", use_fast=False)\n",
    "slow_tokenizer"
   ],
   "id": "dc250c6f0ec933c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:34:03.994052Z",
     "start_time": "2024-06-24T08:34:02.849834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# 单条循环处理\n",
    "for i in range(10000):\n",
    "    fast_tokenizer(sen)"
   ],
   "id": "baefbe0353468a93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.12 s\n",
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:34:15.867819Z",
     "start_time": "2024-06-24T08:34:14.099437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# 单条循环处理\n",
    "for i in range(10000):\n",
    "    slow_tokenizer(sen)"
   ],
   "id": "fb4b2e274d02fa37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.72 s\n",
      "Wall time: 1.76 s\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:34:26.390172Z",
     "start_time": "2024-06-24T08:34:26.043099Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# 处理batch数据\n",
    "res = fast_tokenizer([sen] * 10000)"
   ],
   "id": "a2a28be746a22a68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.28 s\n",
      "Wall time: 340 ms\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:34:35.216214Z",
     "start_time": "2024-06-24T08:34:33.699489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# 处理batch数据\n",
    "res = slow_tokenizer([sen] * 10000)"
   ],
   "id": "76b458f504dcf80c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.45 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:34:47.420871Z",
     "start_time": "2024-06-24T08:34:47.400926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = fast_tokenizer(sen, return_offsets_mapping=True)\n",
    "inputs"
   ],
   "id": "9c5210368814a825",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 10252, 8221, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 12), (12, 15), (15, 16), (0, 0)]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:34:55.045205Z",
     "start_time": "2024-06-24T08:34:55.030245Z"
    }
   },
   "cell_type": "code",
   "source": "inputs.word_ids()",
   "id": "be602c0179e40646",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:35:09.017242Z",
     "start_time": "2024-06-24T08:35:07.853701Z"
    }
   },
   "cell_type": "code",
   "source": "inputs = slow_tokenizer(sen, return_offsets_mapping=True)",
   "id": "4ca9e9d7fe869367",
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mslow_tokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43msen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_offsets_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2883\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2881\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[0;32m   2882\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[1;32m-> 2883\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_one(text\u001B[38;5;241m=\u001B[39mtext, text_pair\u001B[38;5;241m=\u001B[39mtext_pair, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mall_kwargs)\n\u001B[0;32m   2884\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2885\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2989\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2969\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_encode_plus(\n\u001B[0;32m   2970\u001B[0m         batch_text_or_text_pairs\u001B[38;5;241m=\u001B[39mbatch_text_or_text_pairs,\n\u001B[0;32m   2971\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2986\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2987\u001B[0m     )\n\u001B[0;32m   2988\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2989\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencode_plus(\n\u001B[0;32m   2990\u001B[0m         text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[0;32m   2991\u001B[0m         text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[0;32m   2992\u001B[0m         add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   2993\u001B[0m         padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   2994\u001B[0m         truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[0;32m   2995\u001B[0m         max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   2996\u001B[0m         stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   2997\u001B[0m         is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m   2998\u001B[0m         pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m   2999\u001B[0m         return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   3000\u001B[0m         return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m   3001\u001B[0m         return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m   3002\u001B[0m         return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m   3003\u001B[0m         return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m   3004\u001B[0m         return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m   3005\u001B[0m         return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m   3006\u001B[0m         verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   3007\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3008\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3062\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.encode_plus\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   3052\u001B[0m \u001B[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001B[39;00m\n\u001B[0;32m   3053\u001B[0m padding_strategy, truncation_strategy, max_length, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_padding_truncation_strategies(\n\u001B[0;32m   3054\u001B[0m     padding\u001B[38;5;241m=\u001B[39mpadding,\n\u001B[0;32m   3055\u001B[0m     truncation\u001B[38;5;241m=\u001B[39mtruncation,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3059\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3060\u001B[0m )\n\u001B[1;32m-> 3062\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_encode_plus(\n\u001B[0;32m   3063\u001B[0m     text\u001B[38;5;241m=\u001B[39mtext,\n\u001B[0;32m   3064\u001B[0m     text_pair\u001B[38;5;241m=\u001B[39mtext_pair,\n\u001B[0;32m   3065\u001B[0m     add_special_tokens\u001B[38;5;241m=\u001B[39madd_special_tokens,\n\u001B[0;32m   3066\u001B[0m     padding_strategy\u001B[38;5;241m=\u001B[39mpadding_strategy,\n\u001B[0;32m   3067\u001B[0m     truncation_strategy\u001B[38;5;241m=\u001B[39mtruncation_strategy,\n\u001B[0;32m   3068\u001B[0m     max_length\u001B[38;5;241m=\u001B[39mmax_length,\n\u001B[0;32m   3069\u001B[0m     stride\u001B[38;5;241m=\u001B[39mstride,\n\u001B[0;32m   3070\u001B[0m     is_split_into_words\u001B[38;5;241m=\u001B[39mis_split_into_words,\n\u001B[0;32m   3071\u001B[0m     pad_to_multiple_of\u001B[38;5;241m=\u001B[39mpad_to_multiple_of,\n\u001B[0;32m   3072\u001B[0m     return_tensors\u001B[38;5;241m=\u001B[39mreturn_tensors,\n\u001B[0;32m   3073\u001B[0m     return_token_type_ids\u001B[38;5;241m=\u001B[39mreturn_token_type_ids,\n\u001B[0;32m   3074\u001B[0m     return_attention_mask\u001B[38;5;241m=\u001B[39mreturn_attention_mask,\n\u001B[0;32m   3075\u001B[0m     return_overflowing_tokens\u001B[38;5;241m=\u001B[39mreturn_overflowing_tokens,\n\u001B[0;32m   3076\u001B[0m     return_special_tokens_mask\u001B[38;5;241m=\u001B[39mreturn_special_tokens_mask,\n\u001B[0;32m   3077\u001B[0m     return_offsets_mapping\u001B[38;5;241m=\u001B[39mreturn_offsets_mapping,\n\u001B[0;32m   3078\u001B[0m     return_length\u001B[38;5;241m=\u001B[39mreturn_length,\n\u001B[0;32m   3079\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m   3080\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3081\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\transformers\\lib\\site-packages\\transformers\\tokenization_utils.py:711\u001B[0m, in \u001B[0;36mPreTrainedTokenizer._encode_plus\u001B[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    705\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    706\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not valid. Should be a string, a list/tuple of strings or a list/tuple of\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    707\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m integers.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    708\u001B[0m             )\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_offsets_mapping:\n\u001B[1;32m--> 711\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\n\u001B[0;32m    712\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    713\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    714\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtransformers.PreTrainedTokenizerFast. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    715\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMore information on available tokenizers at \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    716\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://github.com/huggingface/transformers/pull/2674\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    717\u001B[0m     )\n\u001B[0;32m    719\u001B[0m first_ids \u001B[38;5;241m=\u001B[39m get_input_ids(text)\n\u001B[0;32m    720\u001B[0m second_ids \u001B[38;5;241m=\u001B[39m get_input_ids(text_pair) \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h2>特殊Tokenizer的加载</h2>",
   "id": "5d39c09416b04ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:36:00.901741Z",
     "start_time": "2024-06-24T08:36:00.888778Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import AutoTokenizer",
   "id": "b5b6433728cf68ee",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:36:09.659928Z",
     "start_time": "2024-06-24T08:36:03.109045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 新版本的transformers（>4.34），加载 THUDM/chatglm 会报错，因此这里替换为了天宫的模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Skywork/Skywork-13B-base\", trust_remote_code=True)\n",
    "tokenizer"
   ],
   "id": "8df9570f838e2113",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20bb51e6394640f9bb6eca150f90bc31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86166\\anaconda3\\envs\\transformers\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\86166\\.cache\\huggingface\\hub\\models--Skywork--Skywork-13B-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenization_skywork.py:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48d6f79bc40a45c9a38b6009d37a0d96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Skywork/Skywork-13B-base:\n",
      "- tokenization_skywork.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/994k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8d022aa2275454eaad1f8ca1e44aee6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d4c645d8ba344b0c867a4e6d597a8599"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers_modules.Skywork.Skywork-13B-base.bc35915066fbbf15b77a1a4a74e9b574ab167816.tokenization_skywork.SkyworkTokenizer'>. This means that tokens that come after special tokens will not be properly handled. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SkyworkTokenizer(name_or_path='Skywork/Skywork-13B-base', vocab_size=65519, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:46:39.395198Z",
     "start_time": "2024-06-24T08:46:39.369236Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.save_pretrained(\"skywork_tokenizer\")",
   "id": "2c2fe6c8911bc56e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('skywork_tokenizer\\\\tokenizer_config.json',\n",
       " 'skywork_tokenizer\\\\special_tokens_map.json',\n",
       " 'skywork_tokenizer\\\\tokenizer.model',\n",
       " 'skywork_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:46:52.722858Z",
     "start_time": "2024-06-24T08:46:51.687847Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = AutoTokenizer.from_pretrained(\"skywork_tokenizer\", trust_remote_code=True)",
   "id": "a874138ae1a0531",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T08:47:05.646803Z",
     "start_time": "2024-06-24T08:47:05.633836Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(tokenizer.encode(sen))",
   "id": "8247eda17faf7343",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>弱小的我也有大Dreaming!'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-transformers",
   "language": "python",
   "name": "transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
